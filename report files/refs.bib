@inproceedings{spp,
	title = {Path confidence based lookahead prefetching},
	url = {https://ieeexplore.ieee.org/document/7783763},
	doi = {10.1109/MICRO.2016.7783763},
	abstract = {Designing prefetchers to maximize system performance often requires a delicate balance between coverage and accuracy. Achieving both high coverage and accuracy is particularly challenging in workloads with complex address patterns, which may require large amounts of history to accurately predict future addresses. This paper describes the Signature Path Prefetcher (SPP), which offers effective solutions for three classic challenges in prefetcher design. First, SPP uses a compressed history based scheme that accurately predicts complex address patterns. Second, unlike other history based algorithms, which miss out on many prefetching opportunities when address patterns make a transition between physical pages, SPP tracks complex patterns across physical page boundaries and continues prefetching as soon as they move to new pages. Finally, SPP uses the confidence it has in its predictions to adaptively throttle itself on a per-prefetch stream basis. In our analysis, we find that SPP improves performance by 27.2\% over a no-prefetching baseline, and outperforms the state-of-the-art Best Offset prefetcher by 6.4\%. SPP does this with minimal overhead, operating strictly in the physical address space, and without requiring any additional processor core state, such as the PC.},
	urldate = {2024-10-15},
	booktitle = {2016 49th {Annual} {IEEE}/{ACM} {International} {Symposium} on {Microarchitecture} ({MICRO})},
	author = {Kim, Jinchun and Pugsley, Seth H. and Gratz, Paul V. and Reddy, A.L. Narasimha and Wilkerson, Chris and Chishti, Zeshan},
	month = oct,
	year = {2016},
	keywords = {Hardware, Prefetching, Prediction algorithms, History, Memory management, Indexes, Bandwidth},
	pages = {1--12},
}

@inproceedings{ppf,
	title = {Perceptron-{Based} {Prefetch} {Filtering}},
	url = {https://ieeexplore.ieee.org/document/8980306},
	abstract = {Hardware prefetching is an effective technique for hiding cache miss latencies in modern processor designs. Prefetcher performance can be characterized by two main metrics that are generally at odds with one another: coverage, the fraction of baseline cache misses which the prefetcher brings into the cache; and accuracy, the fraction of prefetches which are ultimately used. An overly aggressive prefetcher may improve coverage at the cost of reduced accuracy. Thus, performance may be harmed by this over-aggressiveness because many resources are wasted, including cache capacity and bandwidth. An ideal prefetcher would have both high coverage and accuracy. In this paper, we introduce Perceptron-based Prefetch Filtering (PPF) as a way to increase the coverage of the prefetches generated by an underlying prefetcher without negatively impacting accuracy. PPF enables more aggressive tuning of the underlying prefetcher, leading to increased coverage by filtering out the growing numbers of inaccurate prefetches such an aggressive tuning implies. We also explore a range of features to use to train PPF's perceptron layer to identify inaccurate prefetches. PPF improves performance on a memory-intensive subset of the SPEC CPU 2017 benchmarks by 3.78\% for a single-core configuration, and by 11.4\% for a 4-core configuration, compared to the underlying prefetcher alone.},
	urldate = {2024-10-04},
	booktitle = {2019 {ACM}/{IEEE} 46th {Annual} {International} {Symposium} on {Computer} {Architecture} ({ISCA})},
	author = {Bhatia, Eshan and Chacon, Gino and Pugsley, Seth and Teran, Elvira and Gratz, Paul V. and Jim√©nez, Daniel A.},
	month = jun,
	year = {2019},
	note = {ISSN: 2575-713X},
	pages = {1--13},
}


@misc{radhika_ghosal_writing_nodate,
	title = {Writing a {MachineFunctionPass} in {LLVM}},
	url = {https://www.kharghoshal.xyz/blog/writing-machinefunctionpass},
	urldate = {2024-12-12},
	author = {{Radhika Ghosal}},
	file = {X86MachineInstrPrinter.cpp:/Users/jupiterbradley/Zotero/storage/RMP747R4/writing-machinefunctionpass.html:text/html},
}

@inproceedings{software_prefetch,
	address = {New York, NY, USA},
	series = {{ASPLOS} {VII}},
	title = {Compiler-based prefetching for recursive data structures},
	isbn = {978-0-89791-767-4},
	url = {https://dl.acm.org/doi/10.1145/237090.237190},
	doi = {10.1145/237090.237190},
	abstract = {Software-controlled data prefetching offers the potential for bridging the ever-increasing speed gap between the memory subsystem and today's high-performance processors. While prefetching has enjoyed considerable success in array-based numeric codes, its potential in pointer-based applications has remained largely unexplored. This paper investigates compiler-based prefetching for pointer-based applications---in particular, those containing recursive data structures. We identify the fundamental problem in prefetching pointer-based data structures and propose a guideline for devising successful prefetching schemes. Based on this guideline, we design three prefetching schemes, we automate the most widely applicable scheme (greedy prefetching) in an optimizing research compiler, and we evaluate the performance of all three schemes on a modern superscalar processor similar to the MIPS R10000. Our results demonstrate that compiler-inserted prefetching can significantly improve the execution speed of pointer-based codes---as much as 45\% for the applications we study. In addition, the more sophisticated algorithms (which we currently perform by hand, but which might be implemented in future compilers) can improve performance by as much as twofold. Compared with the only other compiler-based pointer prefetching scheme in the literature, our algorithms offer substantially better performance by avoiding unnecessary overhead and hiding more latency.},
	urldate = {2024-10-07},
	booktitle = {Proceedings of the seventh international conference on {Architectural} support for programming languages and operating systems},
	publisher = {Association for Computing Machinery},
	author = {Luk, Chi-Keung and Mowry, Todd C.},
	month = sep,
	year = {1996},
	pages = {222--233},
	file = {Full Text PDF:/Users/jupiterbradley/Zotero/storage/CB2D5JXN/Luk and Mowry - 1996 - Compiler-based prefetching for recursive data stru.pdf:application/pdf},
}

@misc{static_memdep,
	title = {Improving {Memory} {Dependence} {Prediction} with {Static} {Analysis}},
	url = {http://arxiv.org/abs/2403.08056},
	doi = {10.48550/arXiv.2403.08056},
	abstract = {This paper explores the potential of communicating information gained by static analysis from compilers to Out-of-Order (OoO) machines, focusing on the memory dependence predictor (MDP). The MDP enables loads to issue without all in-flight store addresses being known, with minimal memory order violations. We use LLVM to find loads with no dependencies and label them via their opcode. These labelled loads skip making lookups into the MDP, improving prediction accuracy by reducing false dependencies. We communicate this information in a minimally intrusive way, i.e.{\textasciitilde}without introducing additional hardware costs or instruction bandwidth, providing these improvements without any additional overhead in the CPU. We find that in select cases in Spec2017, a significant number of load instructions can skip interacting with the MDP and lead to a performance gain. These results point to greater possibilities for static analysis as a source of near zero cost performance gains in future CPU designs.},
	urldate = {2024-09-26},
	publisher = {arXiv},
	author = {Panayi, Luke and Gandhi, Rohan and Whittaker, Jim and Chouliaras, Vassilios and Berger, Martin and Kelly, Paul},
	month = jun,
	year = {2024},
	note = {arXiv:2403.08056 [cs]},
	keywords = {B.0, B.8, C.1, Computer Science - Hardware Architecture, Computer Science - Programming Languages},
	file = {arXiv Fulltext PDF:/Users/jupiterbradley/Zotero/storage/KV7NERSZ/Panayi et al. - 2024 - Improving Memory Dependence Prediction with Static.pdf:application/pdf;arXiv.org Snapshot:/Users/jupiterbradley/Zotero/storage/ZJ3K9TD2/2403.html:text/html},
}


@article{hashed_perceptron,
	title = {Merging path and gshare indexing in perceptron branch prediction},
	volume = {2},
	issn = {1544-3566, 1544-3973},
	url = {https://dl.acm.org/doi/10.1145/1089008.1089011},
	doi = {10.1145/1089008.1089011},
	abstract = {We introduce the
              hashed
              perceptron predictor, which merges the concepts behind the gshare, path-based and perceptron branch predictors. This predictor can achieve superior accuracy to a path-based and a global perceptron predictor, previously the most accurate dynamic branch predictors known in the literature. We also show how such a predictor can be ahead pipelined to yield one cycle effective latency. On the SPECint2000 set of benchmarks, the hashed perceptron predictor improves accuracy by up to 15.6\% over a MAC-RHSP and 27.2\% over a path-based neural predictor.},
	language = {en},
	number = {3},
	urldate = {2024-11-19},
	journal = {ACM Transactions on Architecture and Code Optimization},
	author = {Tarjan, David and Skadron, Kevin},
	month = sep,
	year = {2005},
	pages = {280--300},
	file = {Full Text PDF:/Users/jupiterbradley/Zotero/storage/WGF2JCYY/Tarjan and Skadron - 2005 - Merging path and gshare indexing in perceptron bra.pdf:application/pdf},
}
